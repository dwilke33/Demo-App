import streamlit as st
import pandas as pd
import numpy as np
import re
import json

def generate_synthetic_patients(n=300, seed=42):
    rng = np.random.default_rng(seed)

    genders = ["Female", "Male", "Other"]
    diagnoses = [
        "Type 2 Diabetes",
        "Hypertension",
        "Breast Cancer",
        "COPD",
        "Obesity",
        "Hyperlipidemia",
    ]
    meds = ["Metformin", "Lisinopril", "Atorvastatin", "Albuterol", "Insulin", "None"]
    regions = ["US-East", "US-West", "EU-North", "EU-South", "APAC"]

    df = pd.DataFrame(
        {
            "PatientID": [f"P{100000+i}" for i in range(n)],
            "Age": rng.integers(18, 85, size=n),
            "Gender": rng.choice(genders, size=n, p=[0.49, 0.49, 0.02]),
            "Diagnosis": rng.choice(diagnoses, size=n),
            "Biomarker_A": np.round(rng.normal(loc=2.0, scale=0.7, size=n), 2),
            "Biomarker_B": np.round(rng.normal(loc=50, scale=15, size=n), 1),
            "Smoker": rng.choice([0, 1], size=n, p=[0.8, 0.2]),
            "Medications": rng.choice(meds, size=n),
            "Location": rng.choice(regions, size=n),

            # NEW FIELDS â†“â†“â†“
            # Distance to clinic (km): 1â€“80 km
            "DistanceToClinic_km": rng.integers(1, 80, size=n),

            # Rough comorbidity index: 0â€“4
            "ComorbidityIndex": rng.integers(0, 5, size=n),
        }
    )

    # Add small missingness to biomarkers
    mask_a = rng.random(n) < 0.05
    mask_b = rng.random(n) < 0.05
    df.loc[mask_a, "Biomarker_A"] = np.nan
    df.loc[mask_b, "Biomarker_B"] = np.nan

    return df



# -----------------------------
# NLP-lite: protocol parsing
# -----------------------------

# Age patterns: "Age between 40 and 70", "Age 40-70"
AGE_RANGE_RE = re.compile(
    r"age\s*(?:between|from)?\s*(\d{1,3})\s*(?:-|to|and)\s*(\d{1,3})",
    re.IGNORECASE,
)

# "Age >= 40", "Age at least 40"
AGE_MIN_RE = re.compile(
    r"age\s*(?:>=|â‰¥|at least|minimum|min)\s*(\d{1,3})",
    re.IGNORECASE,
)

# "Age <= 70", "Age at most 70"
AGE_MAX_RE = re.compile(
    r"age\s*(?:<=|â‰¤|at most|maximum|max)\s*(\d{1,3})",
    re.IGNORECASE,
)

# Diagnosis / condition line: "Diagnosis: Type 2 Diabetes"
DIAG_RE = re.compile(
    r"(diagnosis|condition)\s*:\s*([a-z0-9 \-\&\/]+)",
    re.IGNORECASE,
)

# Biomarker lines: "Biomarker A >= 1.8", "Biomarker B <= 60"
BIOMARKER_RE = re.compile(
    r"biomarker\s*(A|B)\s*(>=|â‰¤|<=|â‰¥|>|<|=)\s*([0-9]+(?:\.[0-9]+)?)",
    re.IGNORECASE,
)

# "Exclude smokers" or "No smokers"
EXCLUDE_SMOKER_RE = re.compile(
    r"(exclude|no)\s*smokers",
    re.IGNORECASE,
)


def parse_protocol_text(txt: str):
    """
    Very simple, rule-based parser that extracts structured criteria
    from free-text protocol descriptions.
    """
    txt = (txt or "").strip()

    criteria = {
        "age_min": None,
        "age_max": None,
        "diagnosis_required": None,
        "biomarkers": [],  # list of {"name": "A"/"B", "op": ">=", "value": float}
        "exclude_smokers": False,
    }

    # Age range
    m_range = AGE_RANGE_RE.search(txt)
    if m_range:
        criteria["age_min"] = int(m_range.group(1))
        criteria["age_max"] = int(m_range.group(2))
    else:
        # Age min only
        mmin = AGE_MIN_RE.search(txt)
        if mmin:
            criteria["age_min"] = int(mmin.group(1))

        # Age max only
        mmax = AGE_MAX_RE.search(txt)
        if mmax:
            criteria["age_max"] = int(mmax.group(1))

    # Diagnosis / condition
    m_diag = DIAG_RE.search(txt)
    if m_diag:
        criteria["diagnosis_required"] = m_diag.group(2).strip()

    # Biomarkers
    for bm in BIOMARKER_RE.finditer(txt):
        name, op, val = bm.group(1).upper(), bm.group(2), float(bm.group(3))
        # Normalize ops like â‰¥, â‰¤ to >=, <=
        norm_map = {"â‰¥": ">=", "â‰¤": "<=", "<=": "<=", ">=": ">=", ">": ">", "<": "<", "=": "="}
        op = norm_map.get(op, op)
        criteria["biomarkers"].append(
            {
                "name": name,  # "A" or "B"
                "op": op,      # ">=", "<=", etc.
                "value": val,
            }
        )

    # Exclude smokers
    if EXCLUDE_SMOKER_RE.search(txt):
        criteria["exclude_smokers"] = True

    return criteria


# -----------------------------
# Simple rule-based scoring
# -----------------------------

def compare(value, op, threshold):
    """Compare a numeric value to a threshold using a simple operator."""
    if pd.isna(value):
        return None  # treat missing as unknown
    if op == ">=":
        return value >= threshold
    if op == "<=":
        return value <= threshold
    if op == ">":
        return value > threshold
    if op == "<":
        return value < threshold
    if op == "=":
        return abs(value - threshold) < 1e-6
    return None


def score_patients(df: pd.DataFrame, criteria: dict, weight_cfg=None):
    """
    Simple, transparent scoring:
    - Age match: up to 20 points
    - Diagnosis match: 25 points
    - Biomarkers: up to 35 points (shared)
    - Non-smoker when smokers are excluded: 20 points
    """
    if weight_cfg is None:
        weight_cfg = {
            "age": 20,
            "diagnosis": 25,
            "biomarkers_total": 35,   # split equally across listed biomarkers
            "exclude_smokers": 20,
        }

    scores = []
    explanations = []

    n_bio = max(1, len(criteria.get("biomarkers", []))) if criteria.get("biomarkers") else 0
    bio_each = weight_cfg["biomarkers_total"] / n_bio if n_bio > 0 else 0

    for _, row in df.iterrows():
        s = 0.0
        reasons = []

        # ---- Age ----
        age_ok = True
        if criteria.get("age_min") is not None:
            if row["Age"] >= criteria["age_min"]:
                reasons.append(f"+ age >= {criteria['age_min']}")
            else:
                reasons.append(f"- age < {criteria['age_min']}")
                age_ok = False
        if criteria.get("age_max") is not None:
            if row["Age"] <= criteria["age_max"]:
                reasons.append(f"+ age <= {criteria['age_max']}")
            else:
                reasons.append(f"- age > {criteria['age_max']}")
                age_ok = False
        if (criteria.get("age_min") is not None) or (criteria.get("age_max") is not None):
            if age_ok:
                s += weight_cfg["age"]

        # ---- Diagnosis ----
        diag_req = criteria.get("diagnosis_required")
        if diag_req:
            if diag_req.lower() in str(row["Diagnosis"]).lower():
                s += weight_cfg["diagnosis"]
                reasons.append(f"+ diagnosis matches ({diag_req})")
            else:
                reasons.append(f"- diagnosis mismatch (needs {diag_req})")

        # ---- Biomarkers ----
        for bio in criteria.get("biomarkers", []):
            col = f"Biomarker_{bio['name']}"
            val = row.get(col, np.nan)
            comp = compare(val, bio["op"], bio["value"])
            if comp is None:
                reasons.append(f"~ {col} missing")
            elif comp:
                s += bio_each
                reasons.append(f"+ {col} {bio['op']} {bio['value']}")
            else:
                reasons.append(f"- {col} not {bio['op']} {bio['value']} (val={val})")

        # ---- Exclude smokers ----
        if criteria.get("exclude_smokers", False):
            if row["Smoker"] == 0:
                s += weight_cfg["exclude_smokers"]
                reasons.append("+ non-smoker")
            else:
                reasons.append("- smoker (excluded)")

        # Clamp to [0, 100]
        s = float(np.clip(s, 0, 100))
        scores.append(s)
        explanations.append(reasons)

    out = df.copy()
    out["MatchScore"] = np.round(scores, 1)
    out["Explanation"] = [json.dumps(r, ensure_ascii=False) for r in explanations]
    out.sort_values("MatchScore", ascending=False, inplace=True)
    out.reset_index(drop=True, inplace=True)
    return out


# -----------------------------
# Streamlit app
# -----------------------------
st.set_page_config(
    page_title="Clinical Trial Matching PoC",
    page_icon="ðŸ§ª",
    layout="wide"
)

st.title("ðŸ§ª Clinical Trial Patient Matching â€“ PoC")

st.markdown(
    """
This app demonstrates a **simple AI-assisted clinical trial patient matching PoC**
using synthetic EHR-style data.

**Current capabilities**
1. Generates a synthetic patient dataset
2. Accepts mock protocol criteria as free text (or uploaded .txt file)
3. Parses the protocol into structured criteria (NLP-lite)
4. Applies a transparent, rule-based scoring system to rank patients by match
5. Provides a simple chatbot-style interface to query trial criteria
"""
)

# -----------------------------
# Sidebar controls
# -----------------------------
st.sidebar.header("âš™ï¸ Patient Data Settings")
n_patients = st.sidebar.slider(
    "Number of synthetic patients",
    50,
    1000,
    300,
    step=50
)
seed = st.sidebar.number_input(
    "Random seed",
    min_value=0,
    max_value=999999,
    value=42,
    step=1
)

st.sidebar.markdown("---")
st.sidebar.header("ðŸ“„ Protocol Upload (optional)")
uploaded_protocol = st.sidebar.file_uploader(
    "Upload protocol text file (.txt)",
    type=["txt"],
    help="If provided, this will override the default protocol text in the main panel."
)

# -----------------------------
# Generate patient data
# -----------------------------
patients_df = generate_synthetic_patients(n=n_patients, seed=seed)

st.subheader("ðŸ‘¥ Synthetic Patient Dataset")
st.caption("These records are fully synthetic and generated on the fly for PoC purposes.")
st.dataframe(patients_df, use_container_width=True, height=350)

# -----------------------------
# Protocol criteria input
# -----------------------------
st.markdown("---")
st.subheader("ðŸ“‹ Mock Trial Protocol Criteria")

default_protocol = (
    "StudyTitle: Example Metabolic Study\n"
    "Age between 40 and 70\n"
    "Diagnosis: Type 2 Diabetes\n"
    "Biomarker A >= 1.8\n"
    "Biomarker B <= 60\n"
    "Exclude smokers"
)

protocol_text = default_protocol

# If user uploaded a .txt file, use its contents instead of the default
if uploaded_protocol is not None:
    try:
        protocol_text = uploaded_protocol.read().decode("utf-8", errors="ignore")
    except Exception:
        st.warning("Could not read uploaded protocol as UTF-8. Using default text instead.")
        protocol_text = default_protocol

protocol_text = st.text_area(
    "Enter or edit mock protocol text",
    value=protocol_text,
    height=180,
    help=(
        "This represents the free-text eligibility description from a clinical trial protocol.\n"
        "The app parses this into structured criteria and uses it to score patients."
    ),
)

st.markdown("**Current protocol text:**")
st.code(protocol_text, language="text")

# -----------------------------
# Parse protocol text into structured criteria
# -----------------------------
criteria = parse_protocol_text(protocol_text)

st.markdown("**Parsed structured criteria (NLP-lite):**")
st.json(criteria)

# -----------------------------
# Score and rank patients (main view)
# -----------------------------
st.markdown("---")
st.subheader("ðŸ§® Ranked Patient Matches")

min_score = st.slider(
    "Minimum MatchScore to display",
    min_value=0,
    max_value=100,
    value=60,
    step=5,
    help="Filter out patients whose match score is below this threshold."
)

scored_df = score_patients(patients_df, criteria)

# Apply threshold
view = scored_df[scored_df["MatchScore"] >= min_score].copy()

# Filters
c1, c2, c3 = st.columns(3)
with c1:
    gender_filter = st.multiselect(
        "Filter by Gender",
        options=sorted(scored_df["Gender"].dropna().unique().tolist())
    )
with c2:
    diag_filter = st.multiselect(
        "Filter by Diagnosis",
        options=sorted(scored_df["Diagnosis"].dropna().unique().tolist())
    )
with c3:
    loc_filter = st.multiselect(
        "Filter by Location",
        options=sorted(scored_df["Location"].dropna().unique().tolist())
    )

if gender_filter:
    view = view[view["Gender"].isin(gender_filter)]
if diag_filter:
    view = view[view["Diagnosis"].isin(diag_filter)]
if loc_filter:
    view = view[view["Location"].isin(loc_filter)]

st.caption("Patients sorted by MatchScore (highest first).")
st.dataframe(view, use_container_width=True, height=350)

# Simple score distribution chart (all patients)
st.markdown("**MatchScore distribution (all patients)**")
st.bar_chart(scored_df["MatchScore"].value_counts().sort_index())

# Download scored results
csv_data = scored_df.to_csv(index=False)
st.download_button(
    "â¬‡ï¸ Download all scored results (CSV)",
    data=csv_data,
    file_name="scored_patient_matches.csv",
    mime="text/csv",
)

# -----------------------------
# Chatbot-style interface
# -----------------------------
st.markdown("---")
st.subheader("ðŸ’¬ Chatbot-style Trial Criteria Interface")

st.markdown(
    """
Type a natural-language description of trial criteria below.
The assistant will:

1. Parse your message into structured criteria (using the same NLP-lite logic)
2. Score all synthetic patients
3. Reply with parsed criteria and the top 5 matching patients
"""
)

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

chat_input = st.text_input(
    "Describe the trial criteria (e.g., 'Age 45-70 with Type 2 Diabetes, Biomarker A >= 2, exclude smokers')",
    key="chat_input",
)

if st.button("Send", type="primary"):
    user_text = chat_input.strip()
    if user_text:
        # Add user message to history
        st.session_state["chat_history"].append(
            {"role": "user", "text": user_text}
        )

        # Parse & score
        chat_criteria = parse_protocol_text(user_text)
        chat_scored = score_patients(patients_df, chat_criteria)
        top5 = chat_scored.head(5)[["PatientID", "MatchScore", "Age", "Gender", "Diagnosis"]]

        # Build assistant reply text
        reply_lines = []
        reply_lines.append("Parsed criteria:")
        reply_lines.append(json.dumps(chat_criteria, indent=2))
        reply_lines.append("")
        reply_lines.append("Top 5 matching patients (PatientID, MatchScore, Age, Gender, Diagnosis):")
        reply_lines.append(top5.to_string(index=False))

        reply_text = "\n".join(reply_lines)

        st.session_state["chat_history"].append(
            {"role": "assistant", "text": reply_text}
        )

        # Clear input
        st.session_state["chat_input"] = ""

# Display chat history
for msg in st.session_state["chat_history"]:
    if msg["role"] == "user":
        st.markdown(f"**You:** {msg['text']}")
    else:
        st.markdown("**Assistant:**")
        st.code(msg["text"], language="text")

st.info(
    "This chatbot-style interface reuses the same parsing and scoring engine as the main view, "
    "but wraps it in a conversational experience."
)
